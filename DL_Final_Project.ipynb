{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rb9C-D9VJqq"
      },
      "source": [
        "# Getting Started\n",
        "Mount your drive and import modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZtiYpF_S8Qn",
        "outputId": "e83c5740-b9af-4691-c8e3-73ff7e731877"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCZdRFuOUkoJ"
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from skimage import color, io\n",
        "from skimage.color import lab2rgb, rgb2gray\n",
        "\n",
        "from tensorflow.keras.utils import array_to_img, img_to_array, load_img\n",
        "from keras.layers import Conv2D, UpSampling2D, InputLayer, Conv2DTranspose\n",
        "from skimage.io import imsave\n",
        "from keras.models import Sequential\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pickle\n",
        "import random\n",
        "\n",
        "import os\n",
        "# os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wuiLAOrU7XX"
      },
      "source": [
        "# Preprocess Data\n",
        "Run next code block to preprocess data. Remember to download the Flickr 8K dataset from Kaggle and change the paths accordingly: https://www.kaggle.com/datasets/adityajn105/flickr8k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YlciGjCRpvP",
        "outputId": "7c9cf681-bb9e-4df3-ee47-26bcbc52c5fb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2500/2500 [10:25<00:00,  4.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data has been dumped into /content/drive/MyDrive/Colab Notebooks/data/train2.p!\n",
            "Data has been dumped into /content/drive/MyDrive/Colab Notebooks/data/train2_labels.p!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2091/2091 [08:05<00:00,  4.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data has been dumped into /content/drive/MyDrive/Colab Notebooks/data/train3.p!\n",
            "Data has been dumped into /content/drive/MyDrive/Colab Notebooks/data/train3_labels.p!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [03:51<00:00,  4.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data has been dumped into /content/drive/MyDrive/Colab Notebooks/data/test.p!\n",
            "Data has been dumped into /content/drive/MyDrive/Colab Notebooks/data/test_labels.p!\n"
          ]
        }
      ],
      "source": [
        "def process_images(image_names, data_folder):\n",
        "    train_images = []\n",
        "    train_labels = []\n",
        "    \n",
        "    # Create a progress bar for iterating over a list of image_names\n",
        "    pbar = tqdm(image_names)\n",
        " \n",
        "    # Set the description of the current progress bar\n",
        "    # Example: [1/1] Processing 'data/Images/10815824_2997e03d76.jpg': 100%\n",
        "    for i, image_name in enumerate(pbar):\n",
        "        img = f'{data_folder}/Images/{image_name}'\n",
        "        \n",
        "        # The Image class in the Pillow library is used to open images as an np array. 3 means RGB.\n",
        "        with Image.open(img) as img: # print(\"img shape:\", np.shape(img)): (333, 500, 3)\n",
        "            img_array = np.array(img.resize((256,256))) # print(\"img_array shape\", np.shape(img_array)): (256, 256, 3)\n",
        "            \n",
        "        # Convert RGB to LAB\n",
        "        img_lab_rs = color.rgb2lab(1.0/255*img_array) # Shape: (256, 256, 3)\n",
        "        \n",
        "        # Extract Lightness from LAB and convert to tensor \n",
        "        img_l_rs = img_lab_rs[:,:,0]\n",
        "        img_l_rs = img_l_rs.reshape((256, 256, 1))\n",
        "        # tens_rs_l = tf.convert_to_tensor(img_l_rs) # tens_rs_l tf.Tensor([256 256], shape=(2,), dtype=int32)\n",
        "\n",
        "        # Extract A and B from LAB and convert to tensor \n",
        "        img_ab_rs = img_lab_rs[:,:,1:]\n",
        "        img_ab_rs /= 128\n",
        "        # tens_rs_ab = tf.convert_to_tensor(img_ab_rs) # tens_rs_ab tf.Tensor([256 256 2], shape=(3,), dtype=int32)\n",
        "        \n",
        "        train_images += [img_l_rs]\n",
        "        train_labels += [img_ab_rs]\n",
        "\n",
        "    return train_images, train_labels\n",
        "\n",
        "def load_data(data_folder, batch):\n",
        "    train_images = []\n",
        "    train_labels = []\n",
        "\n",
        "    # all_pics = io.ImageCollection(f'{data_folder}/Images/*.jpg', load_func=load_imgs)\n",
        "\n",
        "    text_file_path = f'{data_folder}/captions.txt'\n",
        "    with open(text_file_path) as file:\n",
        "        examples = file.read().splitlines()[1:]\n",
        "\n",
        "    image_names_to_captions = {}\n",
        "\n",
        "    for example in examples:\n",
        "        img_name, caption = example.split(',', 1)\n",
        "        image_names_to_captions[img_name] = image_names_to_captions.get(img_name, []) + [caption]\n",
        "\n",
        "    # shuffle images\n",
        "    shuffled_images = list(image_names_to_captions.keys())\n",
        "    random.seed(0)\n",
        "    random.shuffle(shuffled_images)\n",
        "\n",
        "    # adjust splicing to change batch sizes\n",
        "    if batch == 'train1':\n",
        "        data = shuffled_images[1000:3500]\n",
        "    elif batch == 'train2':\n",
        "        data = shuffled_images[3500:6000]\n",
        "    elif batch == 'train3':\n",
        "        data = shuffled_images[6000:]\n",
        "    else:\n",
        "        data = shuffled_images[:1000]\n",
        "\n",
        "    images, labels = process_images(data, data_folder)\n",
        "\n",
        "    create_pickle(np.array(images), data_folder + batch)\n",
        "    create_pickle(np.array(labels), data_folder + batch + '_labels')\n",
        "\n",
        "def create_pickle(data, file):\n",
        "    with open(f'/{file}.p', 'wb') as pickle_file:\n",
        "        pickle.dump(data, pickle_file)\n",
        "    print(f'Data has been dumped into {file}.p!')\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    ## Download this and put the Images into your ../data directory\n",
        "    ## Flickr 8k Dataset: https://www.kaggle.com/datasets/adityajn105/flickr8k?resource=download\n",
        "\n",
        "    path = '/content/drive/MyDrive/Colab Notebooks/data/'\n",
        "    \n",
        "    load_data(path, 'train1')\n",
        "    # load_data(path, 'train2')\n",
        "    # load_data(path, 'train3')\n",
        "    # load_data(path, 'test')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQcEklVQVTRt"
      },
      "source": [
        "# Model\n",
        "The code block below contains our model. We need to update the architecture and determine which batch size and epochs work best."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFwXt0f7ytcg"
      },
      "source": [
        "## Basic model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ent9ruiKydqQ"
      },
      "outputs": [],
      "source": [
        "def make_basic_model(model):\n",
        "    model.add(InputLayer(input_shape=(None, None, 1)))\n",
        "    model.add(Conv2D(8, (3, 3), activation='relu', padding='same', strides=2))\n",
        "    model.add(Conv2D(8, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(16, (3, 3), activation='relu', padding='same', strides=2))\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same', strides=2))\n",
        "    model.add(UpSampling2D((2, 2)))\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(UpSampling2D((2, 2)))\n",
        "    model.add(Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(UpSampling2D((2, 2)))\n",
        "    model.add(Conv2D(2, (3, 3), activation='tanh', padding='same'))\n",
        "    model.compile(optimizer='adam', loss='mse')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1lWNhbjygj5"
      },
      "source": [
        "## Paper model\n",
        "Next is the model as described in the paper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pHjmy_l6yluS"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Normalization\n",
        "\n",
        "def make_paper_model(model):\n",
        "    model.add(InputLayer(input_shape=(None, None, 1)))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same', strides=2))\n",
        "    model.add(Normalization())\n",
        "\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same', strides=2))\n",
        "    model.add(Normalization())\n",
        "\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same', strides=2))\n",
        "    model.add(Normalization())\n",
        "\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Normalization())\n",
        "\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Normalization())\n",
        "\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Normalization())\n",
        "\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Normalization())\n",
        "\n",
        "    model.add(Conv2DTranspose(256, (4, 4), activation='relu', strides=2))\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(313, (3, 3), activation='softmax', padding='same'))\n",
        "\n",
        "\n",
        "    model.add(UpSampling2D((2, 2)))\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(UpSampling2D((2, 2)))\n",
        "    model.add(Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
        "    # model.add(UpSampling2D((2, 2)))\n",
        "    # model.add(Conv2D(2, (3, 3), activation='tanh', padding='same'))\n",
        "    model.add(tf.keras.layers.Reshape((256, 256)))\n",
        "    model.compile(optimizer='adam', loss='mse')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWZbL5Agy01A"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iT_BgfT9Rtfm",
        "outputId": "33514dcb-da3c-464b-f393-8688f49d0115"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.9386\n",
            "Epoch 2/500\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 0.5051\n",
            "Epoch 3/500\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.5116\n",
            "Epoch 4/500\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.5122\n",
            "Epoch 5/500\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 0.5616\n",
            "Epoch 6/500\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.4707\n",
            "Epoch 7/500\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.4972\n",
            "Epoch 8/500\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.4379\n",
            "Epoch 9/500\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.4288\n",
            "Epoch 10/500\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3927\n",
            "Epoch 11/500\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.3088\n",
            "Epoch 12/500\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.1328\n",
            "Epoch 13/500\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.0402\n",
            "Epoch 14/500\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.0255\n",
            "Epoch 15/500\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.0263\n",
            "Epoch 16/500\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.0258\n",
            "Epoch 17/500\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.0199\n",
            "Epoch 18/500\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.0186\n",
            "Epoch 19/500\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.0195\n",
            "Epoch 20/500\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.0172\n",
            "Epoch 21/500\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.0156\n",
            "Epoch 22/500\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.0168\n",
            "Epoch 23/500\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.0158\n",
            "Epoch 24/500\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.0144\n",
            "Epoch 25/500\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.0140\n",
            "Epoch 26/500\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.0137\n",
            "Epoch 27/500\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.0131\n",
            "Epoch 28/500\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.0127\n",
            "Epoch 29/500\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.0125\n",
            "Epoch 30/500\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.0125\n",
            "Epoch 31/500\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.0124\n",
            "Epoch 32/500\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.0124\n",
            "Epoch 33/500\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.0124\n",
            "Epoch 34/500\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.0123\n",
            "Epoch 35/500\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.0122\n",
            "Epoch 36/500\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.0121\n",
            "Epoch 37/500\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.0121\n",
            "Epoch 38/500\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.0121\n",
            "Epoch 39/500\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.0120\n",
            "Epoch 40/500\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.0120\n",
            "Epoch 41/500\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.0120\n",
            "Epoch 42/500\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.0119\n",
            "Epoch 43/500\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.0119\n",
            "Epoch 44/500\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.0119\n",
            "Epoch 45/500\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.0119\n",
            "Epoch 46/500\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.0118\n",
            "Epoch 47/500\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.0118\n",
            "Epoch 48/500\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.0118\n",
            "Epoch 49/500\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.0118\n",
            "Epoch 50/500\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.0118\n",
            "Epoch 51/500\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.0118\n",
            "Epoch 52/500\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.0117\n",
            "Epoch 53/500\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.0117\n",
            "Epoch 54/500\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 0.0117\n",
            "Epoch 55/500\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.0117\n",
            "Epoch 56/500\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.0117\n",
            "Epoch 57/500\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.0117\n",
            "Epoch 58/500\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.0117\n",
            "Epoch 59/500\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.0117\n",
            "Epoch 60/500\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.0117\n",
            "Epoch 61/500\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.0116\n",
            "Epoch 62/500\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.0116\n",
            "Epoch 63/500\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.0116\n",
            "Epoch 64/500\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.0116\n",
            "Epoch 65/500\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.0116\n",
            "Epoch 66/500\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.0116\n",
            "Epoch 67/500\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.0116\n",
            "Epoch 68/500\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.0116\n",
            "Epoch 69/500\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.0116\n",
            "Epoch 70/500\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 0.0116\n",
            "Epoch 71/500\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.0116\n",
            "Epoch 72/500\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 0.0116\n",
            "Epoch 73/500\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.0116\n",
            "Epoch 74/500\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.0116\n",
            "Epoch 75/500\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.0116\n",
            "Epoch 76/500\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.0116\n",
            "Epoch 77/500\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 0.0116\n",
            "Epoch 78/500\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.0116\n",
            "Epoch 79/500\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.0116\n",
            "Epoch 80/500\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.0115\n",
            "Epoch 81/500\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.0115\n",
            "Epoch 82/500\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.0115\n",
            "Epoch 83/500\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.0115\n",
            "Epoch 84/500\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.0115\n",
            "Epoch 85/500\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.0115\n",
            "Epoch 86/500\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.0115\n",
            "Epoch 87/500\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.0115\n",
            "Epoch 88/500\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 0.0115\n",
            "Epoch 89/500\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.0115\n",
            "Epoch 90/500\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.0115\n",
            "Epoch 91/500\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.0115\n",
            "Epoch 92/500\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.0115\n",
            "Epoch 93/500\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.0115\n",
            "Epoch 94/500\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.0115\n",
            "Epoch 95/500\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.0115\n",
            "Epoch 96/500\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.0115\n",
            "Epoch 97/500\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.0115\n",
            "Epoch 98/500\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.0115\n",
            "Epoch 99/500\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.0115\n",
            "Epoch 100/500\n",
            "1/1 [==============================] - 0s 126ms/step - loss: 0.0115\n",
            "Epoch 101/500\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.0115\n",
            "Epoch 102/500\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.0115\n",
            "Epoch 103/500\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.0115\n",
            "Epoch 104/500\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.0115\n",
            "Epoch 105/500\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.0115\n",
            "Epoch 106/500\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.0115\n",
            "Epoch 107/500\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.0114\n",
            "Epoch 108/500\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.0114\n",
            "Epoch 109/500\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.0114\n",
            "Epoch 110/500\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.0114\n",
            "Epoch 111/500\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.0114\n",
            "Epoch 112/500\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.0114\n",
            "Epoch 113/500\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.0114\n",
            "Epoch 114/500\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.0114\n",
            "Epoch 115/500\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.0114\n",
            "Epoch 116/500\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.0114\n",
            "Epoch 117/500\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.0114\n",
            "Epoch 118/500\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.0114\n",
            "Epoch 119/500\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.0114\n",
            "Epoch 120/500\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.0114\n",
            "Epoch 121/500\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.0114\n",
            "Epoch 122/500\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.0114\n",
            "Epoch 123/500\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.0114\n",
            "Epoch 124/500\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.0114\n",
            "Epoch 125/500\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.0114\n",
            "Epoch 126/500\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.0114\n",
            "Epoch 127/500\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.0114\n",
            "Epoch 128/500\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.0114\n",
            "Epoch 129/500\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.0114\n",
            "Epoch 130/500\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.0114\n",
            "Epoch 131/500\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.0114\n",
            "Epoch 132/500\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.0114\n",
            "Epoch 133/500\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.0113\n",
            "Epoch 134/500\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.0113\n",
            "Epoch 135/500\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.0113\n",
            "Epoch 136/500\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.0113\n",
            "Epoch 137/500\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.0113\n",
            "Epoch 138/500\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 0.0113\n",
            "Epoch 139/500\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.0113\n",
            "Epoch 140/500\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.0113\n",
            "Epoch 141/500\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.0113\n",
            "Epoch 142/500\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.0113\n",
            "Epoch 143/500\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.0113\n",
            "Epoch 144/500\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.0113\n",
            "Epoch 145/500\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.0113\n",
            "Epoch 146/500\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 0.0113\n",
            "Epoch 147/500\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.0113\n",
            "Epoch 148/500\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.0113\n",
            "Epoch 149/500\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.0113\n",
            "Epoch 150/500\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 0.0113\n",
            "Epoch 151/500\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.0113\n",
            "Epoch 152/500\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.0113\n",
            "Epoch 153/500\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.0113\n",
            "Epoch 154/500\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.0113\n",
            "Epoch 155/500\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.0113\n",
            "Epoch 156/500\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.0113\n",
            "Epoch 157/500\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.0112\n",
            "Epoch 158/500\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.0112\n",
            "Epoch 159/500\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.0112\n",
            "Epoch 160/500\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.0112\n",
            "Epoch 161/500\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.0112\n",
            "Epoch 162/500\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.0112\n",
            "Epoch 163/500\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 0.0112\n",
            "Epoch 164/500\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.0112\n",
            "Epoch 165/500\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.0112\n",
            "Epoch 166/500\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.0112\n",
            "Epoch 167/500\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.0112\n",
            "Epoch 168/500\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.0112\n",
            "Epoch 169/500\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.0112\n",
            "Epoch 170/500\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.0112\n",
            "Epoch 171/500\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.0112\n",
            "Epoch 172/500\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.0112\n",
            "Epoch 173/500\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.0112\n",
            "Epoch 174/500\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.0112\n",
            "Epoch 175/500\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.0112\n",
            "Epoch 176/500\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.0112\n",
            "Epoch 177/500\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.0112\n",
            "Epoch 178/500\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.0112\n",
            "Epoch 179/500\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.0112\n",
            "Epoch 180/500\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.0112\n",
            "Epoch 181/500\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.0111\n",
            "Epoch 182/500\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 0.0111\n",
            "Epoch 183/500\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.0111\n",
            "Epoch 184/500\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.0111\n",
            "Epoch 185/500\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.0111\n",
            "Epoch 186/500\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.0111\n",
            "Epoch 187/500\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.0111\n",
            "Epoch 188/500\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.0111\n",
            "Epoch 189/500\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.0111\n",
            "Epoch 190/500\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.0111\n",
            "Epoch 191/500\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.0111\n",
            "Epoch 192/500\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.0111\n",
            "Epoch 193/500\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.0111\n",
            "Epoch 194/500\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.0111\n",
            "Epoch 195/500\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.0111\n",
            "Epoch 196/500\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.0111\n",
            "Epoch 197/500\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.0111\n",
            "Epoch 198/500\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.0111\n",
            "Epoch 199/500\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.0111\n",
            "Epoch 200/500\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.0111\n",
            "Epoch 201/500\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.0111\n",
            "Epoch 202/500\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.0111\n",
            "Epoch 203/500\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.0111\n",
            "Epoch 204/500\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.0111\n",
            "Epoch 205/500\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.0111\n",
            "Epoch 206/500\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.0110\n",
            "Epoch 207/500\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.0110\n",
            "Epoch 208/500\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.0110\n",
            "Epoch 209/500\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.0110\n",
            "Epoch 210/500\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.0110\n",
            "Epoch 211/500\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.0110\n",
            "Epoch 212/500\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.0110\n",
            "Epoch 213/500\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.0110\n",
            "Epoch 214/500\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.0110\n",
            "Epoch 215/500\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.0110\n",
            "Epoch 216/500\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.0110\n",
            "Epoch 217/500\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.0110\n",
            "Epoch 218/500\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.0110\n",
            "Epoch 219/500\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.0110\n",
            "Epoch 220/500\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.0110\n",
            "Epoch 221/500\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.0110\n",
            "Epoch 222/500\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.0110\n",
            "Epoch 223/500\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.0110\n",
            "Epoch 224/500\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.0110\n",
            "Epoch 225/500\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.0110\n",
            "Epoch 226/500\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.0110\n",
            "Epoch 227/500\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.0110\n",
            "Epoch 228/500\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.0110\n",
            "Epoch 229/500\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.0110\n",
            "Epoch 230/500\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.0110\n",
            "Epoch 231/500\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.0110\n",
            "Epoch 232/500\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.0110\n",
            "Epoch 233/500\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.0110\n",
            "Epoch 234/500\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.0109\n",
            "Epoch 235/500\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.0109\n",
            "Epoch 236/500\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.0109\n",
            "Epoch 237/500\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.0109\n",
            "Epoch 238/500\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.0109\n",
            "Epoch 239/500\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.0109\n",
            "Epoch 240/500\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.0109\n",
            "Epoch 241/500\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.0109\n",
            "Epoch 242/500\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.0109\n",
            "Epoch 243/500\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.0109\n",
            "Epoch 244/500\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.0109\n",
            "Epoch 245/500\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.0109\n",
            "Epoch 246/500\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.0109\n",
            "Epoch 247/500\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.0109\n",
            "Epoch 248/500\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.0109\n",
            "Epoch 249/500\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.0109\n",
            "Epoch 250/500\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.0109\n",
            "Epoch 251/500\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.0109\n",
            "Epoch 252/500\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.0109\n",
            "Epoch 253/500\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.0109\n",
            "Epoch 254/500\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.0109\n",
            "Epoch 255/500\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.0109\n",
            "Epoch 256/500\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.0109\n",
            "Epoch 257/500\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.0109\n",
            "Epoch 258/500\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.0109\n",
            "Epoch 259/500\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.0109\n",
            "Epoch 260/500\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.0109\n",
            "Epoch 261/500\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.0109\n",
            "Epoch 262/500\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.0109\n",
            "Epoch 263/500\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 0.0109\n",
            "Epoch 264/500\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.0108\n",
            "Epoch 265/500\n",
            "1/1 [==============================] - 0s 128ms/step - loss: 0.0108\n",
            "Epoch 266/500\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.0108\n",
            "Epoch 267/500\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.0108\n",
            "Epoch 268/500\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.0108\n",
            "Epoch 269/500\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.0108\n",
            "Epoch 270/500\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.0108\n",
            "Epoch 271/500\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.0108\n",
            "Epoch 272/500\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.0108\n",
            "Epoch 273/500\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 0.0108\n",
            "Epoch 274/500\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.0108\n",
            "Epoch 275/500\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.0108\n",
            "Epoch 276/500\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.0108\n",
            "Epoch 277/500\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.0108\n",
            "Epoch 278/500\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 0.0108\n",
            "Epoch 279/500\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.0108\n",
            "Epoch 280/500\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.0108\n",
            "Epoch 281/500\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.0108\n",
            "Epoch 282/500\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.0108\n",
            "Epoch 283/500\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.0108\n",
            "Epoch 284/500\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.0108\n",
            "Epoch 285/500\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.0108\n",
            "Epoch 286/500\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.0108\n",
            "Epoch 287/500\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.0108\n",
            "Epoch 288/500\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.0108\n",
            "Epoch 289/500\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.0108\n",
            "Epoch 290/500\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.0108\n",
            "Epoch 291/500\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.0108\n",
            "Epoch 292/500\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.0108\n",
            "Epoch 293/500\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.0108\n",
            "Epoch 294/500\n",
            "1/1 [==============================] - 0s 128ms/step - loss: 0.0107\n",
            "Epoch 295/500\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.0107\n",
            "Epoch 296/500\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.0107\n",
            "Epoch 297/500\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.0107\n",
            "Epoch 298/500\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.0107\n",
            "Epoch 299/500\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.0107\n",
            "Epoch 300/500\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.0107\n",
            "Epoch 301/500\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.0107\n",
            "Epoch 302/500\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.0107\n",
            "Epoch 303/500\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.0107\n",
            "Epoch 304/500\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.0107\n",
            "Epoch 305/500\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.0107\n",
            "Epoch 306/500\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.0107\n",
            "Epoch 307/500\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.0107\n",
            "Epoch 308/500\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.0107\n",
            "Epoch 309/500\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.0107\n",
            "Epoch 310/500\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.0107\n",
            "Epoch 311/500\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.0107\n",
            "Epoch 312/500\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.0107\n",
            "Epoch 313/500\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.0107\n",
            "Epoch 314/500\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.0107\n",
            "Epoch 315/500\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.0107\n",
            "Epoch 316/500\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.0107\n",
            "Epoch 317/500\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.0107\n",
            "Epoch 318/500\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.0107\n",
            "Epoch 319/500\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.0107\n",
            "Epoch 320/500\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.0107\n",
            "Epoch 321/500\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.0106\n",
            "Epoch 322/500\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.0106\n",
            "Epoch 323/500\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.0106\n",
            "Epoch 324/500\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.0106\n",
            "Epoch 325/500\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.0106\n",
            "Epoch 326/500\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.0106\n",
            "Epoch 327/500\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.0106\n",
            "Epoch 328/500\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.0106\n",
            "Epoch 329/500\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.0106\n",
            "Epoch 330/500\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.0106\n",
            "Epoch 331/500\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.0106\n",
            "Epoch 332/500\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.0106\n",
            "Epoch 333/500\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.0106\n",
            "Epoch 334/500\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.0106\n",
            "Epoch 335/500\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.0106\n",
            "Epoch 336/500\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.0106\n",
            "Epoch 337/500\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.0106\n",
            "Epoch 338/500\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.0106\n",
            "Epoch 339/500\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.0106\n",
            "Epoch 340/500\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.0106\n",
            "Epoch 341/500\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.0106\n",
            "Epoch 342/500\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.0106\n",
            "Epoch 343/500\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.0106\n",
            "Epoch 344/500\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.0106\n",
            "Epoch 345/500\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.0106\n",
            "Epoch 346/500\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.0106\n",
            "Epoch 347/500\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.0106\n",
            "Epoch 348/500\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.0106\n",
            "Epoch 349/500\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.0106\n",
            "Epoch 350/500\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.0106\n",
            "Epoch 351/500\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.0106\n",
            "Epoch 352/500\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.0105\n",
            "Epoch 353/500\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.0105\n",
            "Epoch 354/500\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.0105\n",
            "Epoch 355/500\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.0105\n",
            "Epoch 356/500\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.0105\n",
            "Epoch 357/500\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.0105\n",
            "Epoch 358/500\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.0105\n",
            "Epoch 359/500\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.0105\n",
            "Epoch 360/500\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.0105\n",
            "Epoch 361/500\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.0105\n",
            "Epoch 362/500\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.0105\n",
            "Epoch 363/500\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.0105\n",
            "Epoch 364/500\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.0105\n",
            "Epoch 365/500\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.0105\n",
            "Epoch 366/500\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.0105\n",
            "Epoch 367/500\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.0105\n",
            "Epoch 368/500\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 0.0105\n",
            "Epoch 369/500\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.0105\n",
            "Epoch 370/500\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.0105\n",
            "Epoch 371/500\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.0105\n",
            "Epoch 372/500\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.0105\n",
            "Epoch 373/500\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.0105\n",
            "Epoch 374/500\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.0105\n",
            "Epoch 375/500\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.0105\n",
            "Epoch 376/500\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.0105\n",
            "Epoch 377/500\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.0105\n",
            "Epoch 378/500\n",
            "1/1 [==============================] - 0s 128ms/step - loss: 0.0105\n",
            "Epoch 379/500\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.0105\n",
            "Epoch 380/500\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.0104\n",
            "Epoch 381/500\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.0104\n",
            "Epoch 382/500\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.0104\n",
            "Epoch 383/500\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.0104\n",
            "Epoch 384/500\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.0104\n",
            "Epoch 385/500\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.0104\n",
            "Epoch 386/500\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.0104\n",
            "Epoch 387/500\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.0104\n",
            "Epoch 388/500\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.0104\n",
            "Epoch 389/500\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.0104\n",
            "Epoch 390/500\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.0104\n",
            "Epoch 391/500\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.0104\n",
            "Epoch 392/500\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.0104\n",
            "Epoch 393/500\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.0104\n",
            "Epoch 394/500\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.0104\n",
            "Epoch 395/500\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.0104\n",
            "Epoch 396/500\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.0104\n",
            "Epoch 397/500\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.0104\n",
            "Epoch 398/500\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.0104\n",
            "Epoch 399/500\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.0104\n",
            "Epoch 400/500\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.0104\n",
            "Epoch 401/500\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.0104\n",
            "Epoch 402/500\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.0104\n",
            "Epoch 403/500\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.0104\n",
            "Epoch 404/500\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.0104\n",
            "Epoch 405/500\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.0104\n",
            "Epoch 406/500\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.0104\n",
            "Epoch 407/500\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.0104\n",
            "Epoch 408/500\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.0104\n",
            "Epoch 409/500\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.0104\n",
            "Epoch 410/500\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.0104\n",
            "Epoch 411/500\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.0104\n",
            "Epoch 412/500\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.0104\n",
            "Epoch 413/500\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.0103\n",
            "Epoch 414/500\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.0103\n",
            "Epoch 415/500\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.0103\n",
            "Epoch 416/500\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.0103\n",
            "Epoch 417/500\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.0103\n",
            "Epoch 418/500\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.0103\n",
            "Epoch 419/500\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.0103\n",
            "Epoch 420/500\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.0103\n",
            "Epoch 421/500\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.0103\n",
            "Epoch 422/500\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.0103\n",
            "Epoch 423/500\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.0103\n",
            "Epoch 424/500\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.0103\n",
            "Epoch 425/500\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.0103\n",
            "Epoch 426/500\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.0103\n",
            "Epoch 427/500\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.0103\n",
            "Epoch 428/500\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.0103\n",
            "Epoch 429/500\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.0103\n",
            "Epoch 430/500\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.0103\n",
            "Epoch 431/500\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.0103\n",
            "Epoch 432/500\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.0103\n",
            "Epoch 433/500\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.0103\n",
            "Epoch 434/500\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.0103\n",
            "Epoch 435/500\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.0103\n",
            "Epoch 436/500\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.0103\n",
            "Epoch 437/500\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.0103\n",
            "Epoch 438/500\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.0103\n",
            "Epoch 439/500\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.0103\n",
            "Epoch 440/500\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.0102\n",
            "Epoch 441/500\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.0102\n",
            "Epoch 442/500\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.0102\n",
            "Epoch 443/500\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.0102\n",
            "Epoch 444/500\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.0102\n",
            "Epoch 445/500\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.0102\n",
            "Epoch 446/500\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.0103\n",
            "Epoch 447/500\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.0103\n",
            "Epoch 448/500\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.0103\n",
            "Epoch 449/500\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.0102\n",
            "Epoch 450/500\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.0102\n",
            "Epoch 451/500\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.0102\n",
            "Epoch 452/500\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.0102\n",
            "Epoch 453/500\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.0102\n",
            "Epoch 454/500\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.0102\n",
            "Epoch 455/500\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.0102\n",
            "Epoch 456/500\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.0102\n",
            "Epoch 457/500\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.0102\n",
            "Epoch 458/500\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.0102\n",
            "Epoch 459/500\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.0102\n",
            "Epoch 460/500\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.0102\n",
            "Epoch 461/500\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.0102\n",
            "Epoch 462/500\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.0102\n",
            "Epoch 463/500\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.0102\n",
            "Epoch 464/500\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.0102\n",
            "Epoch 465/500\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 0.0102\n",
            "Epoch 466/500\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.0102\n",
            "Epoch 467/500\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.0102\n",
            "Epoch 468/500\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.0102\n",
            "Epoch 469/500\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.0102\n",
            "Epoch 470/500\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.0102\n",
            "Epoch 471/500\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.0102\n",
            "Epoch 472/500\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.0102\n",
            "Epoch 473/500\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.0101\n",
            "Epoch 474/500\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.0101\n",
            "Epoch 475/500\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.0101\n",
            "Epoch 476/500\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.0102\n",
            "Epoch 477/500\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.0102\n",
            "Epoch 478/500\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.0102\n",
            "Epoch 479/500\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.0102\n",
            "Epoch 480/500\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.0101\n",
            "Epoch 481/500\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.0101\n",
            "Epoch 482/500\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.0101\n",
            "Epoch 483/500\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.0101\n",
            "Epoch 484/500\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.0101\n",
            "Epoch 485/500\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.0101\n",
            "Epoch 486/500\n",
            "1/1 [==============================] - 0s 128ms/step - loss: 0.0101\n",
            "Epoch 487/500\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.0101\n",
            "Epoch 488/500\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.0101\n",
            "Epoch 489/500\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.0101\n",
            "Epoch 490/500\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.0101\n",
            "Epoch 491/500\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.0101\n",
            "Epoch 492/500\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.0101\n",
            "Epoch 493/500\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.0101\n",
            "Epoch 494/500\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.0101\n",
            "Epoch 495/500\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.0101\n",
            "Epoch 496/500\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.0101\n",
            "Epoch 497/500\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.0101\n",
            "Epoch 498/500\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.0101\n",
            "Epoch 499/500\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.0101\n",
            "Epoch 500/500\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.0101\n",
            "4/4 [==============================] - 0s 26ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skimage/_shared/utils.py:394: UserWarning: Color data out of range: Z < 0 in 5 pixels\n",
            "  return func(*args, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.python import train\n",
        "\n",
        "def load_data(file):\n",
        "    with open(f'/{file}.p', 'rb') as data_file:\n",
        "        data = pickle.load(data_file)\n",
        "    return data\n",
        "\n",
        "def main():\n",
        "    model = Sequential()\n",
        "    make_basic_model(model)\n",
        "    # make_paper_model(model)\n",
        "\n",
        "    path = '/content/drive/MyDrive/Colab Notebooks/data'\n",
        "    \n",
        "    # Include the epoch in the file name (uses `str.format`)\n",
        "    checkpoint_path = path + \"/checkpoints/cp-{epoch:04d}.ckpt\"\n",
        "    checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "    batch_size = 64\n",
        "\n",
        "    for i in range(1, 2):\n",
        "        images = load_data(f'{path}/train{i}')\n",
        "        labels = load_data(f'{path}/train{i}_labels')\n",
        "        images = images[:]\n",
        "        labels = labels[:164]\n",
        "        test = images[:100]\n",
        "        test_labels = labels[:100]\n",
        "        images = images[100:]\n",
        "        labels = labels[100:]\n",
        "\n",
        "        history = model.fit(x=images, y=labels, batch_size=batch_size, epochs=500)\n",
        "\n",
        "    output = model.predict(test)\n",
        "    output *= 128\n",
        "\n",
        "    with open(path + '/trainHistoryDict', 'wb') as file_pi:\n",
        "      pickle.dump(history.history, file_pi)\n",
        "\n",
        "    # Output colorizations\n",
        "    for i in range(1, 6):\n",
        "        cur = np.zeros((256, 256, 3))\n",
        "        cur[:,:,0] = test[i][:,:,0]\n",
        "        cur[:,:,1:] = output[i][:,:,:]\n",
        "\n",
        "        cur_gray = rgb2gray(lab2rgb(cur))\n",
        "        cur = lab2rgb(cur)\n",
        "\n",
        "        im = (255*cur).astype(np.uint8)\n",
        "        imgray = (255*cur_gray).astype(np.uint8)\n",
        "        imsave(f\"{path}/DL_images/img_result{i}.png\", im)\n",
        "        # imsave(f\"{path}/DL_images/img_gray_version{i}.png\", imgray)\n",
        "    return\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkDS9vdpFxKP"
      },
      "source": [
        "Run the cell below to plot the loss of the model!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "__pkU8IDepkz",
        "outputId": "794aa7c8-748b-4ba2-9dfb-3797d6ced279"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['loss'])\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "path = '/content/drive/MyDrive/Colab Notebooks/data'\n",
        "\n",
        "with open(path + '/trainHistoryDict', \"rb\") as file_pi:\n",
        "    history = pickle.load(file_pi)\n",
        "\n",
        "print(history.keys())\n",
        "\n",
        "plt.plot(history['loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
